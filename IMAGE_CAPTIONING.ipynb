{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPgPKk64mGFfAa0W3lVdjPI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DAbhishek02/artificial-intelligence-project/blob/main/IMAGE_CAPTIONING.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "sz0gTWrnwQPv"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import pandas as pd\n",
        "import re\n",
        "from scipy.sparse import csr_matrix, vstack\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import Input, Dense, LSTM, Embedding, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UA6M1WuO0tpq",
        "outputId": "782476ed-8434-453e-be75-cace02ebc661"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_images_list = os.listdir('/content/drive/MyDrive/flickr30k_images/flickr30k_images')\n",
        "sample_size = 30\n",
        "train_images_list = train_images_list[:sample_size]\n",
        "\n",
        "size = (224, 224)\n",
        "num_channels = 3\n",
        "train_images = []"
      ],
      "metadata": {
        "id": "6pyh7nZr0UxO"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in train_images_list:\n",
        "    image_path = os.path.join('/content/drive/MyDrive/flickr30k_images/flickr30k_images', i)\n",
        "    img = plt.imread(image_path)\n",
        "    resized_img = cv2.resize(img, size)\n",
        "    train_images.append(resized_img)\n",
        "\n",
        "train_images = np.array([cv2.resize(plt.imread(os.path.join('/content/drive/MyDrive/flickr30k_images/flickr30k_images', i)), size) for i in train_images_list])\n",
        "real_images = train_images.copy()\n",
        "\n",
        "# If the path is correct and the file exists, try using a relative path:\n",
        "# train_captions_df = pd.read_csv('results.csv', delimiter='|')\n",
        "train_captions_df = pd.read_csv('/content/drive/MyDrive/flickr30k_images/results.csv', delimiter='|') # Original Line\n",
        "train_captions_df.columns = ['image_name', 'comment_number', 'comment']\n",
        "print(\"First 5 rows of train_captions_df:\")\n",
        "print(train_captions_df.head())\n",
        "print(\"\\nNumber of rows in train_captions_df:\", len(train_captions_df))\n",
        "print(\"\\nColumn names in train_captions_df:\", train_captions_df.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CmzUTwVbPBf6",
        "outputId": "99bd4793-70e2-4c8e-915d-b1493e04cef0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 5 rows of train_captions_df:\n",
            "       image_name comment_number  \\\n",
            "0  1000092795.jpg              0   \n",
            "1  1000092795.jpg              1   \n",
            "2  1000092795.jpg              2   \n",
            "3  1000092795.jpg              3   \n",
            "4  1000092795.jpg              4   \n",
            "\n",
            "                                             comment  \n",
            "0   Two young guys with shaggy hair look at their...  \n",
            "1   Two young , White males are outside near many...  \n",
            "2   Two men in green shirts are standing in a yard .  \n",
            "3       A man in a blue shirt standing in a garden .  \n",
            "4            Two friends enjoy time spent together .  \n",
            "\n",
            "Number of rows in train_captions_df: 158915\n",
            "\n",
            "Column names in train_captions_df: Index(['image_name', 'comment_number', 'comment'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def images_map_caption(train_images_list, train_captions_df):\n",
        "    caption = []\n",
        "    # Print image names to check if they exist in the dataframe:\n",
        "    print(\"Image names in train_images_list:\")\n",
        "    print(train_images_list)\n",
        "    print(\"\\nImage names in train_captions_df['image_name']:\")\n",
        "    print(train_captions_df['image_name'].unique())\n",
        "    for i in train_images_list:\n",
        "        # Check if image name exists in the dataframe before accessing\n",
        "        if i in train_captions_df['image_name'].values:\n",
        "            caption.append(train_captions_df[train_captions_df['image_name'] == i]['comment'].iat[0])\n",
        "        else:\n",
        "            print(f\"Warning: Image {i} not found in captions dataframe.\")\n",
        "    return caption\n",
        "\n",
        "captions = np.array(images_map_caption(train_images_list, train_captions_df))\n",
        "\n",
        "start_tag = '<s>'\n",
        "end_tag = '<e>'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gNu7Nf9xdaZm",
        "outputId": "f42c65a6-e2da-4911-d302-056fea513a15"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image names in train_images_list:\n",
            "[]\n",
            "\n",
            "Image names in train_captions_df['image_name']:\n",
            "['1000092795.jpg' '10002456.jpg' '1000268201.jpg' ... '997876722.jpg'\n",
            " '99804383.jpg' '998845445.jpg']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = np.array([None] * sample_size)\n",
        "real_images = np.array([None] * sample_size)"
      ],
      "metadata": {
        "id": "1pAU4BcGtV3K"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "j = 0\n",
        "for i in train_images_list:\n",
        "    real_images[j] = np.array(plt.imread('../content/drive/MyDrive/flickr30k_images/flickr30k_images' + i))\n",
        "    train[j] = np.array(plt.imread('../content/drive/MyDrive/flickr30k_images/flickr30k_images' + i))\n",
        "    j += 1"
      ],
      "metadata": {
        "id": "Yu__RKZBteEf"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def images_map_caption(train_images_list, train_captions):\n",
        "    caption = []\n",
        "    for i in train_images_list:\n",
        "        caption.append(train_captions[train_captions['image_name'] == i]['comment'].iat[0])\n",
        "    return caption"
      ],
      "metadata": {
        "id": "_SuaMjs8syih"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "j = 0\n",
        "for i in train_images_list:\n",
        "    # Fix the path by using os.path.join\n",
        "    image_path = os.path.join('/content/drive/MyDrive/flickr30k_images/flickr30k_images', i)\n",
        "    real_images[j] = np.array(plt.imread(image_path))\n",
        "    train[j] = np.array(plt.imread(image_path))\n",
        "    j += 1"
      ],
      "metadata": {
        "id": "87r3hnBiuHuQ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = train_images.copy()  # Assuming you want to stack images in real_images"
      ],
      "metadata": {
        "id": "M9J_hyrHuNO5"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def images_map_caption(train_images_list, train_captions_df):\n",
        "    caption = []\n",
        "    for i in train_images_list:\n",
        "        # Check if there's a match for the current image name\n",
        "        matching_captions = train_captions_df[train_captions_df['image_name'].str.lower() == i.lower()]['comment']\n",
        "    return caption\n",
        "\n",
        "captions = np.array(images_map_caption(train_images_list, train_captions_df))\n",
        "print(\"Shape of captions:\", captions.shape)\n",
        "print(\"First 5 captions:\", captions[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_EgHSkJyiHJN",
        "outputId": "5ba7f3f8-190c-4fbb-a5bf-ba8a7aee1690"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of captions: (0,)\n",
            "First 5 captions: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nFirst 10 entries in train_captions_df['image_name']:\")\n",
        "print(train_captions_df['image_name'].head(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YOVi6Hy9kB-h",
        "outputId": "20d93fce-dd03-49ad-80dc-517b9d717edd"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "First 10 entries in train_captions_df['image_name']:\n",
            "0    1000092795.jpg\n",
            "1    1000092795.jpg\n",
            "2    1000092795.jpg\n",
            "3    1000092795.jpg\n",
            "4    1000092795.jpg\n",
            "5      10002456.jpg\n",
            "6      10002456.jpg\n",
            "7      10002456.jpg\n",
            "8      10002456.jpg\n",
            "9      10002456.jpg\n",
            "Name: image_name, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_vocab(captions):\n",
        "    all_words = []\n",
        "    processed_captions = []\n",
        "    for cap in captions:\n",
        "        cap = re.sub(r' +', ' ', cap)\n",
        "        cap = start_tag + ' ' + cap + ' ' + end_tag\n",
        "        processed_captions.append(cap)\n",
        "        all_words.extend(cap.split())\n",
        "    vocab = sorted(list(set(all_words)))\n",
        "    word_to_index = {word: i for i, word in enumerate(vocab)}\n",
        "    index_to_word = {i: word for word, i in word_to_index.items()}\n",
        "    return vocab, word_to_index, index_to_word, processed_captions\n",
        "\n",
        "if captions.size > 0:\n",
        "    vocab, word_to_index, index_to_word, processed_captions = get_vocab(captions)\n",
        "    vocab_size = len(vocab)\n",
        "    max_caption_length = max(len(cap.split()) for cap in processed_captions)\n",
        "    print(\"\\nVocabulary size:\", vocab_size)\n",
        "    print(\"Max caption length:\", max_caption_length)\n",
        "else:\n",
        "    print(\"\\nError: The 'captions' list is empty. Cannot create vocabulary.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQlFsLhqn1d1",
        "outputId": "174696aa-6ac7-4be1-bc35-d8332a0e870a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Error: The 'captions' list is empty. Cannot create vocabulary.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_input = Input(shape=(224, 224, 3))\n",
        "resnet_model = ResNet50(include_top=False, weights='imagenet')(image_input)\n",
        "image_features = tf.keras.layers.Flatten()(resnet_model)\n",
        "image_features = Dense(256, activation='relu')(image_features) # Reduce dimensionality\n",
        "image_model = Model(inputs=image_input, outputs=image_features)"
      ],
      "metadata": {
        "id": "K_2wliVxPvy1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b97fa3d0-4240-44aa-c1c4-00185385577e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10 # Increase this significantly for meaningful training\n",
        "batch_size = 1"
      ],
      "metadata": {
        "id": "wekp2KqvQAZ6"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_caption(image, image_model, caption_model, word_to_index, index_to_word, max_length):\n",
        "    photo_feature = image_model.predict(np.expand_dims(image, axis=0))\n",
        "    in_text = start_tag\n",
        "    for _ in range(max_length):\n",
        "        sequence = [word_to_index[word] for word in in_text.split() if word in word_to_index]\n",
        "        sequence = pad_sequences([sequence], maxlen=max_length)\n",
        "        yhat = caption_model.predict([sequence, photo_feature]) # Assuming caption model takes both\n",
        "        yhat = np.argmax(yhat)\n",
        "        word = index_to_word.get(yhat)\n",
        "        if word is None or word == end_tag:\n",
        "            break\n",
        "        in_text += ' ' + word\n",
        "    return in_text.replace(start_tag, '').replace(end_tag, '').strip()"
      ],
      "metadata": {
        "id": "Kr99VMqiQVLC"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Model building and preprocessing complete. Training and generation are commented out for now.\")\n",
        "print(\"Remember to uncomment and adjust training parameters for actual learning.\")"
      ],
      "metadata": {
        "id": "z9uGBvb9Qa9t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "098c35be-b38b-4fad-b90c-b07d60bdb6fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model building and preprocessing complete. Training and generation are commented out for now.\n",
            "Remember to uncomment and adjust training parameters for actual learning.\n"
          ]
        }
      ]
    }
  ]
}